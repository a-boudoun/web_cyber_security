
## broken access controll
Access control enforces policy such that users cannot act outside of their intended permissions. Failures typically lead to unauthorized information disclosure, modification, or destruction of all data or performing a business function outside the user's limits.

## robots.txt

A robots.txt file is a simple text file placed in the root directory of a website (e.g., www.example.com/robots.txt) that tells web crawlers, like search engine bots (Googlebot, Bingbot, etc.), which parts of the site they are allowed to crawl or index. It’s part of the Robots Exclusion Protocol (REP), a standard used to control bot behavior. The file uses directives like User-agent, Disallow, and Allow to specify rules.

If you misconfigure or overlook security when setting up your robots.txt file, several risks and attacks can emerge. For example:

1. Exposing Sensitive Directories or Files
Problem: By listing specific endpoints (e.g., Disallow: /api/v1/keys/), you give attackers a roadmap to juicy targets.

2. Information Leakage
Problem: A poorly thought-out robots.txt might reveal development or staging areas you didn’t intend to expose:



